---
title: "Single studies using the CohortMethod package"
author: "Martijn J. Schuemie, Marc A. Suchard and Patrick Ryan"
date: "`r Sys.Date()`"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
vignette: >
  %\VignetteIndexEntry{Single studies using CohortMethod}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
options(width = 200)
library(CohortMethod)
```
# Introduction

This vignette describes how you can use the `CohortMethod` package to perform a single new-user cohort study. We will walk through all the steps needed to perform an exemplar study, and we have selected the well-studied topic of the effect of coxibs versus non-selective non-steroidal anti-inflammatory drugs (NSAIDs) on gastrointestinal (GI) bleeding-related hospitalization. For simplicity, we focus on one coxib -- celecoxib -- and one non-selective NSAID -- diclofenac.

# Installation instructions

Before installing the `CohortMethod` package make sure you have Java available.  Java can be downloaded from [www.java.com](http://www.java.com). For Windows users, RTools is also necessary.  RTools can be downloaded from [CRAN](http://cran.r-project.org/bin/windows/Rtools/).

The `CohortMethod` package is currently maintained in a [Github repository](https://github.com/OHDSI/CohortMethod), and has dependencies on other packages in Github. All of these packages can be downloaded and installed from within R using the `drat` package:

```{r eval=FALSE}
install.packages("remotes")
remotes::install_github("ohdsi/CohortMethod")
```

Once installed, you can type `library(CohortMethod)` to load the package.

# Data extraction

The first step in running the `CohortMethod` is extracting all necessary data from the database server holding the data in the Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) format.

## Configuring the connection to the server

We need to tell R how to connect to the server where the data are. `CohortMethod` uses the `DatabaseConnector` package, which provides the `createConnectionDetails` function. Type `?createConnectionDetails` for the specific settings required for the various database management systems (DBMS). For example, one might connect to a PostgreSQL database using this code:

```{r eval=FALSE}
connectionDetails <- createConnectionDetails(dbms = "postgresql",
                                             server = "localhost/ohdsi",
                                             user = "joe",
                                             password = "supersecret")

cdmDatabaseSchema <- "my_cdm_data"
resultsDatabaseSchema <- "my_results"
options(sqlRenderTempEmulationSchema = NULL)
```

The last two lines define the `cdmDatabaseSchema` and `resultSchema` variables. We'll use these later to tell R where the data in CDM format live, and where we want to write intermediate tables. Note that for Microsoft SQL Server, databaseschemas need to specify both the database and the schema, so for example `cdmDatabaseSchema <- "my_cdm_data.dbo"`.

## Preparing the exposures and outcome(s)

We need to define the exposures and outcomes for our study. One could use an external cohort definition tools, but in this example we do this by writing SQL statements against the OMOP CDM that populate a table of events in which we are interested. The resulting table should have the same structure as the `cohort` table in the CDM. This means it should have the fields `cohort_definition_id`, `cohort_start_date`, `cohort_end_date`,and `subject_id`.

For our example study, we have created a file called *coxibVsNonselVsGiBleed.sql* with the following contents:

```sql
/***********************************
File coxibVsNonselVsGiBleed.sql
***********************************/

IF OBJECT_ID('@resultsDatabaseSchema.coxibVsNonselVsGiBleed', 'U') IS NOT NULL
  DROP TABLE @resultsDatabaseSchema.coxibVsNonselVsGiBleed;

CREATE TABLE @resultsDatabaseSchema.coxibVsNonselVsGiBleed (
  cohort_definition_id INT,
  cohort_start_date DATE,
	cohort_end_date DATE,
	subject_id BIGINT
	);

INSERT INTO @resultsDatabaseSchema.coxibVsNonselVsGiBleed (
	cohort_definition_id,
	cohort_start_date,
	cohort_end_date,
	subject_id
	)
SELECT 1, -- Exposure
	drug_era_start_date,
	drug_era_end_date,
	person_id
FROM @cdmDatabaseSchema.drug_era
WHERE drug_concept_id = 1118084;-- celecoxib

INSERT INTO @resultsDatabaseSchema.coxibVsNonselVsGiBleed (
	cohort_definition_id,
	cohort_start_date,
	cohort_end_date,
	subject_id
	)
SELECT 2, -- Comparator
	drug_era_start_date,
	drug_era_end_date,
	person_id
FROM @cdmDatabaseSchema.drug_era
WHERE drug_concept_id = 1124300; --diclofenac

INSERT INTO @resultsDatabaseSchema.coxibVsNonselVsGiBleed (
	cohort_definition_id,
	cohort_start_date,
	cohort_end_date,
	subject_id
	)
SELECT 3, -- Outcome
	condition_start_date,
	condition_end_date,
	condition_occurrence.person_id
FROM @cdmDatabaseSchema.condition_occurrence
INNER JOIN @cdmDatabaseSchema.visit_occurrence
	ON condition_occurrence.visit_occurrence_id = visit_occurrence.visit_occurrence_id
WHERE condition_concept_id IN (
		SELECT descendant_concept_id
		FROM @cdmDatabaseSchema.concept_ancestor
		WHERE ancestor_concept_id = 192671 -- GI - Gastrointestinal haemorrhage
		)
	AND visit_occurrence.visit_concept_id IN (9201, 9203);
```

This is parameterized SQL which can be used by the `SqlRender` package. We use parameterized SQL so we do not have to pre-specify the names of the CDM and result schemas. That way, if we want to run the SQL on a different schema, we only need to change the parameter values; we do not have to change the SQL code. By also making use of translation functionality in `SqlRender`, we can make sure the SQL code can be run in many different environments.

```{r eval=FALSE}
library(SqlRender)
sql <- readSql("coxibVsNonselVsGiBleed.sql")
sql <- render(sql,
              cdmDatabaseSchema = cdmDatabaseSchema,
              resultsDatabaseSchema = resultsDatabaseSchema)
sql <- translate(sql, targetDialect = connectionDetails$dbms)

connection <- connect(connectionDetails)
executeSql(connection, sql)
```

In this code, we first read the SQL from the file into memory. In the next line, we replace the two parameter names with the actual values. We then translate the SQL into the dialect appropriate for the DBMS we already specified in the `connectionDetails`. Next, we connect to the server, and submit the rendered and translated SQL.

If all went well, we now have a table with the events of interest. We can see how many events per type:

```{r eval=FALSE}
sql <- paste("SELECT cohort_definition_id, COUNT(*) AS count",
             "FROM @resultsDatabaseSchema.coxibVsNonselVsGiBleed",
             "GROUP BY cohort_definition_id")
sql <- render(sql, resultsDatabaseSchema = resultsDatabaseSchema)
sql <- translate(sql, targetDialect = connectionDetails$dbms)

querySql(connection, sql)
```
```{r echo=FALSE,message=FALSE}
data.frame(cohort_concept_id = c(1,2,3),count = c(50000,50000,15000))
```

## Extracting the data from the server

Now we can tell `CohortMethod` to define the cohorts based on our events, construct covariates, and extract all necessary data for our analysis.

**Important**: The target and comparator drug must not be included in the covariates, including any descendant concepts. You will need to manually add the drugs and descendants to the `excludedCovariateConceptIds` of the covariate settings. In this example code we exclude all NSAIDs from the covariates by pointing to the concept ID of the NSAID class and specifying `addDescendantsToExclude = TRUE`.

```{r eval=FALSE}
nsaids <- 21603933

# Define which types of covariates must be constructed:
covSettings <- createDefaultCovariateSettings(excludedCovariateConceptIds = nsaids,
                                              addDescendantsToExclude = TRUE)

#Load data:
cohortMethodData <- getDbCohortMethodData(connectionDetails = connectionDetails,
                                          cdmDatabaseSchema = cdmDatabaseSchema,
                                          targetId = 1,
                                          comparatorId = 2,
                                          outcomeIds = 3,
                                          studyStartDate = "",
                                          studyEndDate = "",
                                          exposureDatabaseSchema = resultsDatabaseSchema,
                                          exposureTable = "coxibVsNonselVsGiBleed",
                                          outcomeDatabaseSchema = resultsDatabaseSchema,
                                          outcomeTable = "coxibVsNonselVsGiBleed",
                                          cdmVersion = cdmVersion,
                                          firstExposureOnly = TRUE,
                                          removeDuplicateSubjects = TRUE,
                                          restrictToCommonPeriod = FALSE,
                                          washoutPeriod = 180,
                                          covariateSettings = covSettings)
cohortMethodData
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/cohortMethodData.zip")) {
  cohortMethodData <- loadCohortMethodData("s:/temp/cohortMethodVignette/cohortMethodData.zip")
}
```
\fontsize{8}{10}
\selectfont
```{r echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/cohortMethodData.zip")) {
  cohortMethodData
}
```
\fontsize{10}{12}
\selectfont

There are many parameters, but they are all documented in the `CohortMethod` manual. The `createDefaultCovariateSettings` function is described in the `FeatureExtraction` package. In short, we are pointing the function to the table created earlier and indicating which concept IDs in that table identify the target, comparator and outcome. We instruct that the default set of covariates should be constructed, including covariates for all conditions, drug exposures, and procedures that were found on or before the index date. To customize the set of covariates, please refer to the `FeatureExtraction` package vignette by typing `vignette("UsingFeatureExtraction", package="FeatureExtraction")`.

All data about the cohorts, outcomes, and covariates are extracted from the server and stored in the `cohortMethodData` object. This object uses the `Andromeda` package to store information in a way that ensures R does not run out of memory, even when the data are large. We can use the generic `summary()` function to view some more information of the data we extracted:

```{r eval=FALSE}
summary(cohortMethodData)
```
```{r echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/cohortMethodData.zip")) {
  summary(cohortMethodData)
}
```

### Saving the data to file

Creating the `cohortMethodData` file can take considerable computing time, and it is probably a good idea to save it for future sessions. Because `cohortMethodData` uses `Andromeda`, we cannot use R's regular save function. Instead, we'll have to use the `saveCohortMethodData()` function:

```{r eval=FALSE}
saveCohortMethodData(cohortMethodData, "coxibVsNonselVsGiBleed.zip")
```

We can use the `loadCohortMethodData()` function to load the data in a future session.

### Defining new users ###

Typically, a new user is defined as first time use of a drug (either target or comparator), and typically a washout period (a minimum number of days prior first use) is used to make sure it is truly first use. When using the `CohortMethod` package, you can enforce the necessary requirements for new use in three ways:

1. When creating the cohorts in the database, for example when using a cohort definition tool.
2. When loading the cohorts using the `getDbCohortMethodData` function, you can use the `firstExposureOnly`, `removeDuplicateSubjects`, `restrictToCommonPeriod`, and `washoutPeriod` arguments. (As shown in the example above).
3. When defining the study population using the `createStudyPopulation` function (see below) using the `firstExposureOnly`, `removeDuplicateSubjects`, `restrictToCommonPeriod`, and `washoutPeriod` arguments.

The advantage of option 1 is that the input cohorts are already fully defined outside of the `CohortMethod` package, and for example external cohort characterization tools can be used on the same cohorts used in this package. The advantage of options 2 and 3 is that it saves you the trouble of limiting to first use yourself, for example allowing you to directly use the `drug_era` table in the CDM. Option 2 is more efficient than 3, since only data for first use will be fetched, while option 3 is less efficient but allows you to compare the original cohorts to the study population.

# Defining the study population

Typically, the exposure cohorts and outcome cohorts will be defined independently of each other. When we want to produce an effect size estimate, we need to further restrict these cohorts and put them together, for example by removing exposed subjects that had the outcome prior to exposure, and only keeping outcomes that fall within a defined risk window. For this we can use the `createStudyPopulation` function:

```{r eval=FALSE}
studyPop <- createStudyPopulation(cohortMethodData = cohortMethodData,
                                  outcomeId = 3,
                                  firstExposureOnly = FALSE,
                                  restrictToCommonPeriod = FALSE,
                                  washoutPeriod = 0,
                                  removeDuplicateSubjects = "keep all",
                                  removeSubjectsWithPriorOutcome = TRUE,
                                  minDaysAtRisk = 1,
                                  riskWindowStart = 0,
                                  startAnchor = "cohort start",
                                  riskWindowEnd = 30,
                                  endAnchor = "cohort end")
```

Note that we've set `firstExposureOnly` and `removeDuplicateSubjects` to FALSE, and `washoutPeriod` to zero because we already filtered on these arguments when using the `getDbCohortMethodData` function. During loading we set `restrictToCommonPeriod` to FALSE, and we do the same here because we do not want to force the comparison to restrict only to time when both drugs are recorded. We specify the outcome ID we will use, and that people with outcomes prior to the risk window start date will be removed. The risk window is defined as starting at the cohort start date (the index date, `riskWindowStart = 0` and `startAnchor = "cohort start"`), and the risk windows ends 30 days after the cohort ends (`riskWindowEnd = 30` and `endAnchor = "cohort end"`). Note that the risk windows are truncated at the end of observation or the study end date. We also remove subjects who have no time at risk. To see how many people are left in the study population we can always use the `getAttritionTable` function:

```{r eval=FALSE}
getAttritionTable(studyPop)
```
\fontsize{8}{10}
\selectfont
```{r echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/studyPop.rds")) {
  studyPop <- readRDS("s:/temp/cohortMethodVignette/studyPop.rds")
  table <- getAttritionTable(studyPop)
  truncLeft <- function(x, n){
    nc <- nchar(x)
    x[nc > (n - 3)] <- paste(substr(table$description[nc > (n - 3)], 1, n - 3), '...')
    x
  }
  table$description <- truncLeft(table$description,30)
  table
}
```
\fontsize{10}{12}
\selectfont

One additional filtering step that is often used is matching or trimming on propensity scores, as will be discussed next.

# Propensity scores

The `CohortMethod` can use propensity scores to adjust for potential confounders. Instead of the traditional approach of using a handful of predefined covariates, `CohortMethod` typically uses thousands to millions of covariates that are automatically constructed based on conditions, procedures and drugs in the records of the subjects.

## Fitting a propensity model

We can fit a propensity model using the covariates constructed by the `getDbcohortMethodData()` function:

```{r eval=FALSE}
ps <- createPs(cohortMethodData = cohortMethodData, population = studyPop)
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  ps <- readRDS("s:/temp/cohortMethodVignette/ps.rds")
}
```

The `createPs()` function uses the `Cyclops` package to fit a large-scale regularized logistic regression.

To fit the propensity model, `Cyclops` needs to know the hyperparameter value which specifies the variance of the prior. By default `Cyclops` will use cross-validation to estimate the optimal hyperparameter. However, be aware that this can take a really long time. You can use the `prior` and `control` parameters of the `createPs()` to specify `Cyclops` behavior, including using multiple CPUs to speed-up the cross-validation.

## Propensity score diagnostics

We can compute the area under the receiver-operator curve (AUC) for the propensity score model:

```{r eval=FALSE}
computePsAuc(ps)
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  0.81;#computePsAuc(ps)
}
```

We can also plot the propensity score distribution, although we prefer the preference score distribution:

```{r eval=FALSE}
plotPs(ps, 
       scale = "preference", 
       showCountsLabel = TRUE, 
       showAucLabel = TRUE, 
       showEquiposeLabel = TRUE)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  plotPs(ps, scale = "preference", showCountsLabel = TRUE, showAucLabel = TRUE, showEquiposeLabel = TRUE)
}
```

It is also possible to inspect the propensity model itself by showing the covariates that have non-zero coefficients:

```{r eval=FALSE}
getPsModel(ps, cohortMethodData)
```
```{r echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/cohortMethodData.zip")) {
  propensityModel <- getPsModel(ps, cohortMethodData)
  truncRight <- function(x, n){
    nc <- nchar(x)
    x[nc > (n - 3)] <- paste('...',substr(x[nc > (n - 3)], nc[nc > (n - 3)] - n + 1, nc[nc > (n - 3)]),sep = "")
    x
  }
  propensityModel$covariateName <- truncRight(as.character(propensityModel$covariateName), 40)
  head(propensityModel)
  }
```

One advantage of using the regularization when fitting the propensity model is that most coefficients will shrink to zero and fall out of the model. It is a good idea to inspect the remaining variables for anything that should not be there, for example variations of the drugs of interest that we forgot to exclude.

## Using the propensity score

We can use the propensity scores to trim, stratify, match, or weigh our population. For example, one could  trim to equipoise, meaning only subjects with a preference score between 0.25 and 0.75 are kept:

```{r eval=FALSE}
trimmedPop <- trimByPsToEquipoise(ps)
plotPs(trimmedPop, ps, scale = "preference")
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  trimmedPop <- trimByPsToEquipoise(ps)
  plotPs(trimmedPop, ps, scale = "preference")
}
```

Instead (or additionally), we could stratify the population based on the propensity score:

```{r eval=FALSE}
stratifiedPop <- stratifyByPs(ps, numberOfStrata = 5)
plotPs(stratifiedPop, ps, scale = "preference")
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  stratifiedPop <- stratifyByPs(ps, numberOfStrata = 5)
  plotPs(stratifiedPop, ps, scale = "preference")
}
```

We can also match subjects based on propensity scores. In this example, we're using one-to-one matching:

```{r eval=FALSE}
  matchedPop <- matchOnPs(ps, caliper = 0.2, caliperScale = "standardized logit", maxRatio = 1)
  plotPs(matchedPop, ps)
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  matchedPop <- matchOnPs(ps, caliper = 0.2, caliperScale = "standardized logit", maxRatio = 1)
  plotPs(matchedPop, ps)
}
```

Note that for both stratification and matching it is possible to specify additional matching criteria such as age and sex using the `stratifyByPsAndCovariates()` and `matchOnPsAndCovariates()` functions, respectively.

We can see the effect of trimming and/or matching on the population using the `getAttritionTable` function:

```{r eval=FALSE}
getAttritionTable(matchedPop)
```
\fontsize{8}{10}
\selectfont
```{r echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  getAttritionTable(matchedPop)
  table <- getAttritionTable(matchedPop)
  truncLeft <- function(x, n){
    nc <- nchar(x)
    x[nc > (n - 3)] <- paste(substr(table$description[nc > (n - 3)], 1, n - 3), '...')
    x
  }
  table$description <- truncLeft(table$description,30)
  table
}
```
\fontsize{10}{12}
\selectfont

Or, if we like, we can plot an attrition diagram:

```{r eval=FALSE}
drawAttritionDiagram(matchedPop)
```
```{r echo=FALSE,message=FALSE,eval=TRUE,fig.width=5,fig.height=6}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel3.rds")) {
  drawAttritionDiagram(matchedPop)
}
```

## Evaluating covariate balance

To evaluate whether our use of the propensity score is indeed making the two cohorts more comparable, we can compute the covariate balance before and after trimming, matching, and/or stratifying:

```{r eval=FALSE}
balance <- computeCovariateBalance(matchedPop, cohortMethodData)
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/balance.rds")) {
  balance <- readRDS("s:/temp/cohortMethodVignette/balance.rds")
}
```
```{r eval=FALSE}
plotCovariateBalanceScatterPlot(balance, showCovariateCountLabel = TRUE, showMaxLabel = TRUE)
```
```{r echo=FALSE,message=FALSE,eval=TRUE,fig.width=7,fig.height=4.5}
if (file.exists("s:/temp/cohortMethodVignette/balance.rds")) {
  plotCovariateBalanceScatterPlot(balance, 
                                  showCovariateCountLabel = TRUE, 
                                  showMaxLabel = TRUE)
}
```
```{r eval=FALSE}
plotCovariateBalanceOfTopVariables(balance)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE,fig.width=8,fig.height=5}
if (file.exists("s:/temp/cohortMethodVignette/balance.rds")) {
  plotCovariateBalanceOfTopVariables(balance)
}
```

The 'before matching' population is the population as extracted by the `getDbCohortMethodData` function, so before any further filtering steps.

## Inspecting select population characteristics

It is customary to include a table in your paper that lists some select population characteristics before and after matching/stratification/trimming. This is usually the first table, and so will be referred to as 'table 1'. To generate this table, you can use the `createCmTable1` function:

```{r eval=FALSE}
createCmTable1(balance)
```
\fontsize{6.5}{6.5}
\selectfont
```{r comment=NA,echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/balance.rds")) {
  table1 <- createCmTable1(balance)
  print(table1, row.names = FALSE, right = FALSE)
}
```
\fontsize{10}{12}
\selectfont

## Inserting the population cohort in the database ##

For various reasons it might be necessary to insert the study population back into the database, for example because we want to use an external cohort characterization tool. We can use the `insertDbPopulation` function for this purpose:

```{r eval=FALSE}
insertDbPopulation(population = matchedPop,
                   cohortIds = c(101,100),
                   connectionDetails = connectionDetails,
                   cohortDatabaseSchema = resultsDatabaseSchema,
                   cohortTable = "coxibVsNonselVsGiBleed",
                   createTable = FALSE,
                   cdmVersion = cdmVersion)
```

This function will store the population in a table with the same structure as the `cohort` table in the CDM, in this case in the same table where we had created our original cohorts.


# Follow-up and power

Before we start fitting an outcome model, we might be interested to know whether we have sufficient power to detect a
particular effect size. It makes sense to perform these power calculations once the study population has been fully defined,
so taking into account loss to the various inclusion and exclusion criteria (such as no prior outcomes), and loss due to matching and/or trimming. Since the sample size is fixed in retrospective studies (the data has already been collected), and the true effect size is unknown, the CohortMethod package provides a function to compute the minimum detectable relative risk (MDRR) instead:

```{r eval=FALSE}
computeMdrr(population = studyPop,
            modelType = "cox",
            alpha = 0.05,
            power = 0.8,
            twoSided = TRUE)
```
\fontsize{6.5}{6.5}
\selectfont
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/studyPop.rds")) {
computeMdrr(population = studyPop,
            modelType = "cox",
            alpha = 0.05,
            power = 0.8,
            twoSided = TRUE)
}
```
\fontsize{10}{12}
\selectfont

In this example we used the `studyPop` object, so the population before any matching or trimming. If we want to know the MDRR after matching, we use the `matchedPop` object we created earlier instead:

```{r eval=FALSE}
computeMdrr(population = matchedPop,
            modelType = "cox",
            alpha = 0.05,
            power = 0.8,
            twoSided = TRUE)
```
\fontsize{6.5}{6.5}
\selectfont
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/studyPop.rds")) {
computeMdrr(population = matchedPop,
            modelType = "cox",
            alpha = 0.05,
            power = 0.8,
            twoSided = TRUE)
}
```
\fontsize{10}{12}
\selectfont

Even thought the MDRR in the matched population is higher, meaning we have less power, we should of course not be fooled: matching most likely eliminates confounding, and is therefore preferred to not matching.

To gain a better understanding of the amount of follow-up available we can also inspect the distribution of follow-up time. We defined follow-up time as time at risk, so not censored by the occurrence of the outcome. The `getFollowUpDistribution` can provide a simple overview:

```{r eval=FALSE}
getFollowUpDistribution(population = matchedPop)
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/studyPop.rds")) {
getFollowUpDistribution(population = matchedPop)
}
```

The output is telling us number of days of follow-up each quantile of the study population has. We can also plot the distribution:

```{r eval=FALSE}
plotFollowUpDistribution(population = matchedPop)
```
```{r echo=FALSE,message=FALSE,eval=TRUE,fig.width=8,fig.height=5}
if (file.exists("s:/temp/cohortMethodVignette/studyPop.rds")) {
plotFollowUpDistribution(population = matchedPop)
}
```

# Outcome models

The outcome model is a model describing which variables are associated with the outcome.

## Fitting a simple outcome model

In theory we could fit an outcome model without using the propensity scores. In this example we are fitting an outcome model using a Cox regression:

```{r eval=FALSE}
outcomeModel <- fitOutcomeModel(population = studyPop,
                                modelType = "cox")
outcomeModel
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel1.rds")) {
  outcomeModel <- readRDS("s:/temp/cohortMethodVignette/OutcomeModel1.rds")
  outcomeModel
}
```

But of course we want to make use of the matching done on the propensity score:

```{r eval=FALSE}
outcomeModel <- fitOutcomeModel(population = matchedPop,
                                modelType = "cox",
                                stratified = TRUE)
outcomeModel
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel2.rds")) {
  outcomeModel <- readRDS("s:/temp/cohortMethodVignette/OutcomeModel2.rds")
  outcomeModel
}
```

Note that we define the sub-population to be only those in the `matchedPop` object, which we created earlier by matching on the propensity score. We also now use a stratified Cox model, conditioning on the propensity score match sets.

Instead of matching or stratifying we can also perform Inverse Probability of Treatment Weighting (IPTW):
```{r eval=FALSE}
outcomeModel <- fitOutcomeModel(population = ps,
                                modelType = "cox",
                                inversePtWeighting = TRUE)
outcomeModel
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel2w.rds")) {
  outcomeModel <- readRDS("s:/temp/cohortMethodVignette/OutcomeModel2w.rds")
  outcomeModel
}
```


## Adding interaction terms

We may be interested whether the effect is different across different groups in the population. To explore this, we may include interaction terms in the model. In this example we include three interaction terms:

```{r eval=FALSE}
interactionCovariateIds <- c(8532001, 201826210, 21600960413) 
# 8532001 = Female
# 201826210 = Type 2 Diabetes
# 21600960413 = Concurent use of antithrombotic agents
outcomeModel <- fitOutcomeModel(population = matchedPop,
                                modelType = "cox",
                                stratified = TRUE,
                                interactionCovariateIds = interactionCovariateIds)
outcomeModel
```
\fontsize{5.5}{5.5}
\selectfont
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel4.rds")) {
  outcomeModel <- readRDS("s:/temp/cohortMethodVignette/OutcomeModel4.rds")
  outcomeModel
}
```
\fontsize{10}{12}
\selectfont

Note that you can use the `grepCovariateNames` to find covariate IDs.

It is prudent to verify that covariate balance has also been achieved in the subgroups of interest. For example, we can check the covariate balance in the subpopulation of females:

```{r eval=FALSE}
balanceFemale <- computeCovariateBalance(population = matchedPop, 
                                         cohortMethodData = cohortMethodData, 
                                         subgroupCovariateId = 8532001)
plotCovariateBalanceScatterPlot(balanceFemale)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE,fig.width=8,fig.height=5}
if (file.exists("s:/temp/cohortMethodVignette/balanceFemale.rds")) {
  balanceFemale <- readRDS("s:/temp/cohortMethodVignette/balanceFemale.rds")
  plotCovariateBalanceScatterPlot(balanceFemale)
}
```

## Adding covariates to the outcome model

One final refinement would be to use the same covariates we used to fit the propensity model to also fit the outcome model. This way we are more robust against misspecification of the model, and more likely to remove bias. For this we use the regularized Cox regression in the `Cyclops` package. (Note that the treatment variable is automatically excluded from regularization.)

```{r eval=FALSE}
outcomeModel <- fitOutcomeModel(population = matchedPop,
                                cohortMethodData = cohortMethodData,
                                modelType = "cox",
                                stratified = TRUE,
                                useCovariates = TRUE)
outcomeModel
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel3.rds")) {
  outcomeModel <- readRDS("s:/temp/cohortMethodVignette/OutcomeModel3.rds")
  outcomeModel
}
```

## Inspecting the outcome model

We can inspect more details of the outcome model:

```{r eval=FALSE}
exp(coef(outcomeModel))
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel3.rds")) {
  exp(coef(outcomeModel))
}
```

```{r eval=FALSE}
exp(confint(outcomeModel))
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel3.rds")) {
  exp(confint(outcomeModel))
}
```

We can also see the covariates that ended up in the outcome model:

```{r eval=FALSE}
getOutcomeModel(outcomeModel, cohortMethodData)
```
```{r echo=FALSE,message=FALSE}
if (file.exists("s:/temp/cohortMethodVignette/OutcomeModel3.rds")) {
  outcomeModel <- getOutcomeModel(outcomeModel, cohortMethodData)
  truncRight <- function(x, n){
    nc <- nchar(x)
    x[nc > (n - 3)] <- paste('...',substr(x[nc > (n - 3)], nc[nc > (n - 3)] - n + 1, nc[nc > (n - 3)]),sep = "")
    x
  }
  outcomeModel$name <- truncRight(as.character(outcomeModel$name), 40)
  outcomeModel
}
```

## Kaplan-Meier plot

We can create the Kaplan-Meier plot:

```{r eval=FALSE}
plotKaplanMeier(matchedPop, includeZero = FALSE)
```
```{r echo=FALSE, message=FALSE, results='hide'}
if (file.exists("s:/temp/cohortMethodVignette/ps.rds")) {
  plotKaplanMeier(matchedPop, includeZero = FALSE)
}
```

Note that the Kaplan-Meier plot will automatically adjust for any stratification, matching, or trimming that may have been applied.

## Time-to-event plot

We can also plot time-to-event, showing both events before and after the index date, and events during and outside the defined time-at-risk window. This plot can provide insight into the temporal pattern of the outcome relative to the exposures:

```{r eval=FALSE}
plotTimeToEvent(cohortMethodData = cohortMethodData,
                outcomeId = 3,
                firstExposureOnly = FALSE,
                washoutPeriod = 0,
                removeDuplicateSubjects = FALSE,
                minDaysAtRisk = 1,
                riskWindowStart = 0,
                startAnchor = "cohort start",
                riskWindowEnd = 30,
                endAnchor = "cohort end")

```
```{r echo=FALSE, message=FALSE, results='hide'}
if (file.exists("s:/temp/cohortMethodVignette/cohortMethodData.zip")) {
  plotTimeToEvent(cohortMethodData = cohortMethodData,
                  outcomeId = 3,
                  firstExposureOnly = FALSE,
                  washoutPeriod = 0,
                  removeDuplicateSubjects = FALSE,
                  minDaysAtRisk = 1,
                  riskWindowStart = 0,
                  startAnchor = "cohort start",
                  riskWindowEnd = 30,
                  endAnchor = "cohort end")
  
}
```

Note that this plot does not show any adjustment for the propensity score.

# Acknowledgments

Considerable work has been dedicated to provide the `CohortMethod` package.

```{r eval=TRUE}
citation("CohortMethod")
```

Further, `CohortMethod` makes extensive use of the `Cyclops` package.

```{r eval=TRUE}
citation("Cyclops")
```

This work is supported in part through the National Science Foundation grant IIS 1251151.
